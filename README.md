# Demand Forecasting with Synthetic Data

This project demonstrates a complete workflow for forecasting the demand for products using synthetic time‑series data.  It has been developed as an educational case study and implements the full DS/ML pipeline: data generation, baseline modelling, neural network training and deployment in a simple user interface.

## Overview

The dataset is synthetically generated to emulate realistic retail sales patterns: seasonality, long‑term trends and weekly effects.  The codebase includes:

1. **Data generation** (`generate_data.py`): Produces a CSV file containing daily sales for several products over a configurable time span.
2. **Baseline modelling** (`train_baseline.py`): Computes a naïve moving‑average forecast and evaluates its mean absolute error (MAE).
3. **Neural network training** (`train_nn.py`): Uses scikit‑learn's `MLPRegressor` to train a multi‑layer perceptron for each product.  Models and scalers are serialized to a pickle file.
4. **User interface** (`app.py`): A Tkinter application that lets you select a product or load your own CSV file and generates a demand forecast with a corresponding plot.

Although this repository opts for a desktop GUI using Tkinter (for simplicity and minimal dependencies), the same forecasting logic can be adapted to other interfaces such as Streamlit or a REST API.

## Getting Started

### Prerequisites

Ensure you have Python ≥ 3.8 installed.  The required Python packages are listed in `requirements.txt`.  Install them with:

```bash
pip install -r requirements.txt
```

If you are unable to install additional packages, check whether `pandas`, `numpy`, `matplotlib` and `scikit‑learn` are already available in your environment.

### 1. Generate Synthetic Data

Run the data generation script to create a CSV file with synthetic sales records:

```bash
python generate_data.py --output sales_data.csv --num-days 1000 --seed 42
```

This creates a `sales_data.csv` file with 1 000 days of sales for three products (Product A, B and C).  Each row contains the date, product name, simulated price and number of units sold.

### 2. Evaluate Baseline Model

The baseline uses a simple moving‑average forecast with a window of seven days.  To evaluate its performance:

```bash
python train_baseline.py --data sales_data.csv --window 7
```

The script splits each product’s time series into an 80 % training portion and a 20 % test portion, computes a one‑step moving‑average forecast for each test point and reports the mean absolute error (MAE).

### 3. Train Neural Network Models

Train an MLP regression model for each product:

```bash
python train_nn.py --data sales_data.csv --window 7 --output models.pkl
```

This script converts the univariate time series into supervised learning samples (windows of seven consecutive days), splits them into train and test sets, trains an MLPRegressor and reports the MAE for each product.  The trained models and their scalers are saved to `models.pkl`.

### 4. Launch the Forecasting Application

Start the Tkinter GUI with:

```bash
python app.py
```

When the application launches you can:

1. **Select a product** from the drop‑down list (Product A, B or C) and click **Generate Forecast**.  The application will plot the past 60 days of actual sales together with the next 14‑day forecast generated by the corresponding neural network model.
2. **Load a custom CSV**: Click **Load CSV** and choose a file containing your own sales history.  The file must have at least two columns: one with dates (named `date` or `ds`) and one with sales values (named `sales`, `y` or `value`).  The application will compute a 14‑day forecast using a naïve moving‑average baseline and plot it along with the historical data.

The plot includes grid lines, legends and axis labels for easy interpretation.

## File Structure

```
.
├── generate_data.py    # Synthetic data generator
├── train_baseline.py   # Baseline moving-average model
├── train_nn.py         # Neural network training script
├── app.py              # Tkinter forecasting GUI
├── sales_data.csv      # Generated dataset (created after running generate_data.py)
├── models.pkl          # Trained models (created by train_nn.py)
├── requirements.txt    # Python dependencies
└── README.md           # Project documentation
```

## Notes

- The neural network uses scikit‑learn’s `MLPRegressor`.  For more sophisticated forecasting (e.g., LSTM networks), libraries such as PyTorch or TensorFlow could be integrated, but they are heavier and may require additional installation steps.
- The choice of a desktop GUI over a web app is intentional in this environment: it avoids external dependencies and internet access while still providing an interactive interface.  If you wish to deploy the model as a web service, the same core logic can be wrapped in Flask, FastAPI or Streamlit.